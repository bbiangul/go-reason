# GoReason v2 Evaluation Report

## Changes from v1

### Code Improvements
- **Chunk size**: 512 -> 1024 tokens (overlap 64 -> 128)
- **Graph concurrency**: 4 -> 8 workers
- **Per-chunk timeout**: 90s (was unlimited)
- **Skip trivial chunks**: Chunks <50 chars skipped for graph extraction
- **Multi-step entity extraction**: Entities extracted first, then relationships
- **Regex pre-extraction**: Extract entities from structured patterns before LLM
- **Few-shot examples**: Added examples to entity extraction prompts
- **Identifier-aware routing**: Route technical identifiers to graph search
- **Embedding overflow fix**: Truncate texts >24K chars + per-text fallback on batch failure
- **Community detection fix**: Cap modularity algorithm at 200 nodes, incremental strength tracking, max 20 passes
- **Concurrent community summarization**: 8 goroutines instead of sequential (was process-killing bottleneck)
- **Observability logging**: slog-based structured logging across all pipeline stages

### Provider Support
- Added OpenRouter, Groq, OpenAI, LMStudio providers (v1 only had Ollama + OpenRouter)

## Runs Summary

| Run | Embed Fails | Pass Rate | Chat Model | Provider | Graph Build | Total Ingestion |
|-----|-------------|-----------|------------|----------|-------------|-----------------|
| v1 | unknown | **93.3%** (28/30) | qwen/qwen3-30b-a3b | OpenRouter | ~1h45m | ~1h49m |
| v2 | 238 (25%) | 13.3% (4/30) | openai/gpt-oss-120b | Groq | ~6m | ~12m35s |
| v2b | 9 (0.9%) | 16.7% (5/30) | openai/gpt-oss-120b | Groq | ~6m | ~13m |
| **v2c** | **9 (0.9%)** | **33.3%** (10/30) | qwen/qwen3-32b | Groq | 19m16s | 21m33s |

## v2c Configuration (Final Run)

| Parameter | Value |
|-----------|-------|
| **Chat Provider** | Groq |
| **Chat Model** | `qwen/qwen3-32b` |
| **Embedding Provider** | Ollama (local) |
| **Embedding Model** | `nomic-embed-text` (768 dim) |
| **Max Chunk Tokens** | 1024 |
| **Chunk Overlap** | 128 |
| **Max Reasoning Rounds** | 3 |
| **Max Retrieval Results** | 20 |
| **Graph Concurrency** | 8 |
| **Per-Chunk Timeout** | 90s |

## Document

- **File:** Manual Tecnico ALTAVision AV-FM RevG02.1.pdf
- **Language:** Spanish (technical industrial manual)
- **Pages:** 214

## v2c Results: ALTAVision Easy - Single Fact Lookup

| Metric | Value |
|--------|-------|
| **Total Tests** | 30 |
| **Passed** | 10 |
| **Failed** | 20 |
| **Pass Rate** | **33.3%** |

### Aggregate Metrics

| Metric | v2c Score | v1 Score |
|--------|-----------|----------|
| Avg Faithfulness | 1.000 | 0.993 |
| Avg Relevance | 0.057 | 0.128 |
| Avg Accuracy | 0.300 | 0.917 |
| Avg Citation Quality | 0.727 | 0.700 |
| Avg Confidence | 0.965 | 0.948 |

### Category Breakdown

| Category | Faithfulness | Relevance | Accuracy | Citation Quality | Confidence |
|----------|-------------|-----------|----------|-----------------|------------|
| Components (12 tests) | 1.000 | 0.088 | 0.250 | 0.742 | 0.962 |
| Safety (1 test) | 1.000 | 0.000 | 0.000 | 0.600 | 1.000 |
| Specs (17 tests) | 1.000 | 0.038 | 0.353 | 0.724 | 0.965 |

### Token Usage

| Metric | Tokens |
|--------|--------|
| Prompt Tokens | 43,338 |
| Completion Tokens | 12,267 |
| **Total Tokens** | **55,605** |
| Avg Tokens/Query | ~1,853 |

### Pipeline Metrics

| Stage | Duration | Details |
|-------|----------|---------|
| Parsing | 324ms | 471 sections |
| Chunking | 3ms | 942 chunks |
| Embeddings | 10.4s | 933/942 succeeded (9 too long for context) |
| Graph Build | 19m16s | 498/517 succeeded, 19 failed (timeouts/parse errors) |
| Community Detection | instant | 410 components, 454 communities |
| Community Summarization | ~2m | 454/454 succeeded (8-way concurrent) |
| **Total Ingestion** | **21m33s** | 5x faster than v1 |

## Detailed Results

| # | Question | Category | Accuracy | Confidence | Tokens | Pass |
|---|----------|----------|----------|------------|--------|------|
| 1 | Operating temperature range | specs | 1.0 | 1.0 | 2,011 | Y |
| 2 | Tracker board part number | components | **0.0** | 1.0 | 1,386 | **N** |
| 3 | Equipment operating voltage | specs | **0.0** | 1.0 | 1,450 | **N** |
| 4 | Noise emission level | specs | **0.0** | 1.0 | 1,574 | **N** |
| 5 | Air pressure requirement | specs | 1.0 | 1.0 | 2,254 | Y |
| 6 | Inspection bridge material | specs | 0.5 | 1.0 | 1,613 | Y |
| 7 | Weight of Model A Standard | specs | **0.0** | 1.0 | 1,542 | **N** |
| 8 | IP protection rating | specs | **0.0** | 1.0 | 1,508 | **N** |
| 9 | THD level required | specs | **0.0** | 1.0 | 1,568 | **N** |
| 10 | Tracker board IP address | components | **0.0** | 1.0 | 1,418 | **N** |
| 11 | Subnet mask of the Tracker | components | **0.0** | 1.0 | 1,332 | **N** |
| 12 | Fuse rating for Tracker outputs | components | **0.0** | 0.85 | 1,655 | **N** |
| 13 | CPU CUBE processor | components | **0.0** | 1.0 | 1,274 | **N** |
| 14 | Preinstalled operating system | components | 1.0 | 1.0 | 1,767 | Y |
| 15 | Encoder part number | components | **0.0** | 0.85 | 2,805 | **N** |
| 16 | Trigger sensor part number | components | 1.0 | 1.0 | 3,136 | Y |
| 17 | Standard cap diameter | specs | 1.0 | 0.85 | 2,219 | Y |
| 18 | Tracker board inputs | components | **0.0** | 1.0 | 1,664 | **N** |
| 19 | Tracker board outputs | components | **0.0** | 1.0 | 1,510 | **N** |
| 20 | Tracker power supply voltage | components | **0.0** | 1.0 | 1,355 | **N** |
| 21 | Power consumption without AC | specs | **0.0** | 1.0 | 1,320 | **N** |
| 22 | Power consumption with AC | specs | **0.0** | 1.0 | 1,442 | **N** |
| 23 | Cut protection level for gloves | safety | **0.0** | 1.0 | 2,431 | **N** |
| 24 | Wire gauge for cabling | specs | 0.5 | 1.0 | 1,455 | Y |
| 25 | Cabinet paint color | specs | 1.0 | 0.85 | 2,463 | Y |
| 26 | Protection window glass type | specs | **0.0** | 0.85 | 1,640 | **N** |
| 27 | Weight of Model B cabinet | specs | **0.0** | 1.0 | 1,435 | **N** |
| 28 | Weight of Model C Standard XL | specs | **0.0** | 1.0 | 1,442 | **N** |
| 29 | Document revision date | specs | 1.0 | 0.85 | 2,015 | Y |
| 30 | Encoder pulses per revolution | components | 1.0 | 0.85 | 4,921 | Y |

## Analysis

### Regression Root Cause: Model Quality

The accuracy drop from v1 (93.3%) to v2c (33.3%) is **entirely model-driven**:

1. **v1 used `qwen/qwen3-30b-a3b` via OpenRouter** -- this model excels at Spanish technical content extraction and reasoning
2. **v2c used `qwen/qwen3-32b` via Groq** -- despite being a larger model (32B vs 30B), it performs significantly worse on fact extraction from Spanish technical documents
3. **v2/v2b used `openai/gpt-oss-120b` via Groq** -- even worse (13-17%), despite being 120B parameters

### Evidence: Retrieval vs Model

- **Faithfulness is perfect** (1.000) -- the model never halluccinates
- **Accuracy is low** (0.300) -- the model fails to find facts that exist in the retrieved context
- **Failure pattern**: 20/30 failures show the model saying "the context does not contain this information" when it does
- **Embedding fix had minimal impact**: v2 (25% embed failures) -> v2b (0.9% failures) only improved 13.3% -> 16.7%

### Infrastructure Improvements (Working)

Despite the model regression, the v2 codebase improvements are validated:

| Improvement | Status |
|-------------|--------|
| Embedding overflow fix | 25% -> 0.9% failure rate |
| Ingestion speed | 1h49m -> 21m33s (5x faster) |
| Community detection | Was CPU-hanging, now instant |
| Community summarization | Was process-killing (384 sequential), now 2min (8-way concurrent) |
| Graph build concurrency | 4 -> 8 workers, with per-chunk timeout |
| Observability | Full slog-based progress tracking |

### Next Steps

1. **Re-run with `qwen/qwen3-30b-a3b` via OpenRouter** to get a fair v1-vs-v2 comparison with the same model
2. Fix FOREIGN KEY constraint failures in graph builder (entities failing to link to chunks)
3. Consider keeping a model compatibility matrix for provider/model selection
